{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without use a explicit for loop.\n",
    "\n",
    "* Forward propagation\n",
    "* Backpropagation\n",
    "\n",
    "unroll all these pixel values.\n",
    "\n",
    "X = [255, 251,  ..., 255, 134, ...] (64*64*3)  \n",
    "Y = [$y^{1}$, $y^{2}$, $y^{3}$, $y^{4}$, $y^{5}$, ...]\n",
    "\n",
    "x $\\Large \\longrightarrow$ y\n",
    "\n",
    "\n",
    "Notation\n",
    "\n",
    "m tranining examples\n",
    "\n",
    "M_test = #test examples\n",
    "M = M_train\n",
    "\n",
    "$x \\epsilon R^{nx}$\n",
    "\n",
    "$X \\epsilon R^{nx x m}$\n",
    "\n",
    "$Y \\epsilon R^{1, m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x  = \\hat{y} = P(y=1|x)$$\n",
    "\n",
    "parameters \n",
    "\n",
    "$w \\epsilon R ^{nx}, b\\epsilon R$\n",
    "\n",
    "Output $\\hat{y} = \\sigma (w^Tx + b)$\n",
    "\n",
    "$0 \\leq \\hat{y} \\leq 1$\n",
    "\n",
    "Sigmoid\n",
    "\n",
    "$\\sigma(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "if z large $\\sigma(z) = 1$  \n",
    "if z large negative $\\sigma(z) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want $\\hat{y}^{(i)} = y{(i)}$\n",
    "\n",
    "$z^{i} = w^Tx^{i} + b$\n",
    "\n",
    "i-th example\n",
    "\n",
    "\n",
    "Loss (error) functions:\n",
    "\n",
    "$L(\\hat{y}, y) = \\frac{1}{2} (\\hat{y} - y)^2$ (Non - convex)\n",
    "\n",
    "$L(\\hat{y}, y) = -\\left(ylog\\hat{y}+ (1-y)log(1-\\hat{y})\\right)$\n",
    "\n",
    "Cost function\n",
    "\n",
    "$J(w, b) = \\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y}, y) = \\frac{-1}{m} \\sum^{m}_{i=1}[\\left(y^{i}log\\hat{y}^{i}+ (1-y^{i})log(1-\\hat{y}^{i})\\right)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat {\n",
    "$$w : = w - \\alpha \\frac{\\partial J(w, b)}{\\partial w}$$\n",
    "\n",
    "$$w : = w - \\alpha \\frac{\\partial J(w, b)}{\\partial b}$$\n",
    "\n",
    "\n",
    "$$dw = \\frac{\\partial J(w, b)}{\\partial w}$$\n",
    "\n",
    "$$db = \\frac{\\partial J(w, b)}{\\partial b}$$\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align='left' src='images/computing_derivatives.PNG' width='800'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z = w_zx_1 + w_2x_2 + b$\n",
    "\n",
    "$L(\\hat{y}, y) =-\\left(ylog\\hat{y}+ (1-y)log(1-\\hat{y})\\right)$\n",
    "\n",
    "$\\hat{y}  =  a$\n",
    "$\\hat{y} = a = \\sigma(z)$\n",
    "\n",
    "\n",
    "$$da = \\frac{dL(a, y)}{da} = -\\frac{y}{a}+\\frac{1-y}{1-a}$$\n",
    "\n",
    "$$\\frac{da}{dz} =  a (1 -a) = \\frac{d}{dz}\\left(\\frac{1}{1+e^{-z}}\\right)$$\n",
    "\n",
    "$$dz = \\frac{dL(a, y)}{dz} = a - y$$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_1} = \"dw_1\" = x_1 * dz$$\n",
    "$$\\frac{\\partial L}{\\partial w_2} = \"dw_2\" = x_1 * dz$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b} = \"db\" = dz$$\n",
    "\n",
    "\n",
    "$w_1 = w_1 - \\alpha dw_1$  \n",
    "$w_2 = w_1 - \\alpha dw_2$  \n",
    "$b = b - \\alpha db$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent on m examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J(w, b) = \\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y}, y) = \\frac{-1}{m} \\sum^{m}_{i=1}[\\left(y^{i}log\\hat{y}^{i}+ (1-y^{i})log(1-\\hat{y}^{i})\\right)]$\n",
    "\n",
    "\n",
    "$a{i} = \\hat{y}^{i} = \\sigma(z^{i}) = \\sigma(w^Tx^{i}+b)$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial}{\\partial w_1}J(w, b) = \\frac{1}{m}\\sum_{i=1}^{m}\\frac{\\partial}{\\partial w_1}L(\\hat{y}, y) $$\n",
    "\n",
    "\n",
    "$$dw^{i} = \\frac{\\partial}{\\partial w_1}L(\\hat{y}, y) $$\n",
    "\n",
    "\n",
    "<img align='left' src='images/gradient_descent_m_examples.PNG' width='800'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized version:1.9958019256591797 ms\n",
      "For Loop:687.1130466461182 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "tic = time.time() \n",
    "c=np.dot(a, b) \n",
    "toc  =  time.time()\n",
    "print(\"Vectorized version:\" + str(1000*(toc-tic)) +\" ms\")\n",
    "\n",
    "c=0 \n",
    "tic  =  time.time()\n",
    "for i in range(1000000):\n",
    "    c += a[i]*b[i]\n",
    "toc  =  time.time()\n",
    "print(\"For Loop:\" + str(1000*(toc-tic)) +\" ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing Logistic Regression's Gradient Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Broadcasting in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code run faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note on python/numpy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e380b9311a4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# a.shape = (4, 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# b.shape = (3, 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (3,2) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randn(4, 3) # a.shape = (4, 3)\n",
    "b = np.random.randn(3, 2) # b.shape = (3, 2)\n",
    "c = a * b\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
